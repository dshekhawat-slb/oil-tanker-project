{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5881c72",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11669f3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 22:10:27.038489: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-29 22:10:27.038525: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac24465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import cv2\n",
    "\n",
    "class CustomGen(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, img_path, img_path_mask, batch_size):\n",
    "        self.img_path = img_path\n",
    "        self.img_path_mask = img_path_mask\n",
    "        self.batch_size = batch_size\n",
    "        self.list_elements = os.listdir(self.img_path)\n",
    "        self.list_elements_mask = os.listdir(self.img_path_mask)\n",
    "\n",
    "    def __len__(self):\n",
    "#         self.list_elements = os.listdir(self.img_path)\n",
    "#         self.list_elements_mask = os.listdir(self.img_path_mask)\n",
    "        return len(self.list_elements) // self.batch_size\n",
    "\n",
    "    def __getitem__(self,idx):        \n",
    "        X_paths = self.list_elements[idx * self.batch_size:(idx+1) * self.batch_size]\n",
    "        y_paths = self.list_elements_mask[idx * self.batch_size:(idx+1) * self.batch_size]\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for x_filename in X_paths:\n",
    "            X.append(load_img(self.img_path + x_filename))\n",
    "            y_filename = x_filename.replace('.jpg','_mask.jpg')\n",
    "            y_path = self.img_path_mask + y_filename\n",
    "            file_exists = exists(y_path)\n",
    "            if file_exists:\n",
    "                # y.append(load_img('../data/Oil Tanks/image_patches/'+x_filename))\n",
    "                temp_y = np.array(load_img(y_path))[:, :, 0:1]\n",
    "                y.append(temp_y)\n",
    "            else:\n",
    "#                 import ipdb; ipdb.set_trace()\n",
    "                img = cv2.imread(self.img_path + x_filename)\n",
    "                black_img = (img*0)[:, :, 0:1]\n",
    "                y.append(black_img)\n",
    "\n",
    "        return np.stack(X)/255., np.stack(y)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "841efb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../data/Oil Tanks/image_patches/'\n",
    "img_path_mask = '../data/case1_tanks/output_mask'\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f1c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = CustomGen(img_path, img_path_mask, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493b45db",
   "metadata": {},
   "source": [
    "### Test Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdbcac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data_loader.__getitem__(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X[0])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(y[0], cmap ='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape, y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118393fa",
   "metadata": {},
   "source": [
    "### UNET Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bc2610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from PIL import Image\n",
    "import PIL \n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ff9fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(img_size, num_classes):\n",
    "    inputs = layers.Input(shape = img_size + (3,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (512,512)\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = get_model(img_size, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b95d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4fe100",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(X, y,\n",
    "          batch_size=2,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654363b2",
   "metadata": {},
   "source": [
    "### image resize in-progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4bef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.image import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb14c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data prep\n",
    "\n",
    "image_temp = cv2.imread('../data/Oil Tanks/image_patches/01_0_0.jpg')\n",
    "image_temp2 =  cv2.imread('../data/Oil Tanks/image_patches/01_0_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ffbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_temp_resized = resize(\n",
    "    image_temp,\n",
    "    [256,256],\n",
    "    preserve_aspect_ratio=True,\n",
    "    antialias=False,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d18231",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_temp_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c007861",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_temp_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf4b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_temp_resized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
